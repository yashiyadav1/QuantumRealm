{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPioq3nNvImIEaHKgSJCB6Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"KR4sZ5rvzsu9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725230528653,"user_tz":240,"elapsed":32283,"user":{"displayName":"Yashi Yadav","userId":"11532312682170910132"}},"outputId":"6122227d-45bb-462c-fb23-56e6e2a93004"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting qiskit\n","  Downloading qiskit-1.2.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting qiskit-aer\n","  Downloading qiskit_aer-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.15.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n","Collecting gymnasium\n","  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n","Collecting stable-baselines3\n","  Downloading stable_baselines3-2.3.2-py3-none-any.whl.metadata (5.1 kB)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n","Collecting rustworkx>=0.15.0 (from qiskit)\n","  Downloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n","Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.13.2)\n","Collecting dill>=0.3 (from qiskit)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (2.8.2)\n","Collecting stevedore>=3.0.0 (from qiskit)\n","  Downloading stevedore-5.3.0-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit) (4.12.2)\n","Collecting symengine>=0.11 (from qiskit)\n","  Downloading symengine-0.11.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.2 kB)\n","Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.10/dist-packages (from qiskit-aer) (5.9.5)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (9.0.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n","Collecting farama-notifications>=0.0.1 (from gymnasium)\n","  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.16.0)\n","Collecting pbr>=2.0.0 (from stevedore>=3.0.0->qiskit)\n","  Downloading pbr-6.1.0-py2.py3-none-any.whl.metadata (3.4 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Downloading qiskit-1.2.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading qiskit_aer-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n","Downloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading stevedore-5.3.0-py3-none-any.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading symengine-0.11.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (39.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.4/39.4 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pbr-6.1.0-py2.py3-none-any.whl (108 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.5/108.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: farama-notifications, symengine, rustworkx, pbr, gymnasium, dill, stevedore, stable-baselines3, qiskit, qiskit-aer\n","Successfully installed dill-0.3.8 farama-notifications-0.0.4 gymnasium-0.29.1 pbr-6.1.0 qiskit-1.2.0 qiskit-aer-0.15.0 rustworkx-0.15.1 stable-baselines3-2.3.2 stevedore-5.3.0 symengine-0.11.0\n"]}],"source":["# Install required packages\n","!pip install qiskit qiskit-aer matplotlib numpy scipy plotly pandas scikit-learn torch gymnasium stable-baselines3 pillow"]},{"cell_type":"code","source":["import os\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Set up the path for saving the model\n","path = \"/content/drive/My Drive/Colab Notebooks/Quantum Realm/models/\"\n","os.makedirs(path, exist_ok=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":371},"id":"x1xPdVCFv4vX","executionInfo":{"status":"error","timestamp":1725230532617,"user_tz":240,"elapsed":3974,"user":{"displayName":"Yashi Yadav","userId":"11532312682170910132"}},"outputId":"896e0ab6-778c-4a09-b8fb-cf2ef6f4d264"},"execution_count":2,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-5c805cfb674d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Mount Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Set up the path for saving the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]},{"cell_type":"code","source":["\n","\n","\n","import io\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from qiskit import QuantumCircuit, transpile\n","from qiskit_aer import Aer\n","from qiskit.visualization import plot_state_qsphere\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","\n","def generate_quantum_state(num_qubits):\n","    qc = QuantumCircuit(num_qubits)\n","    for _ in range(np.random.randint(1, 5)):\n","        qubit = np.random.randint(0, num_qubits)\n","        gate = np.random.choice(['h', 'x', 'y', 'z'])\n","        if gate == 'h':\n","            qc.h(qubit)\n","        elif gate == 'x':\n","            qc.x(qubit)\n","        elif gate == 'y':\n","            qc.y(qubit)\n","        else:\n","            qc.z(qubit)\n","\n","    backend = Aer.get_backend('statevector_simulator')\n","    transpiled_qc = transpile(qc, backend)\n","    job = backend.run(transpiled_qc)\n","    result = job.result()\n","    statevector = result.get_statevector()\n","    return statevector\n","\n","def quantum_state_to_image(statevector):\n","    fig, ax = plt.subplots(figsize=(5, 5))\n","    plot_state_qsphere(statevector, ax=ax)\n","\n","    # Save the plot to a buffer\n","    buf = io.BytesIO()\n","    plt.savefig(buf, format='png')\n","    plt.close(fig)\n","\n","    # Convert the buffer to an image\n","    buf.seek(0)\n","    image = Image.open(buf)\n","    image = image.convert('RGB')\n","\n","    # Convert to numpy array\n","    image_array = np.array(image)\n","    return image_array"],"metadata":{"id":"RAp5IcK2zwpe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Generator(nn.Module):\n","    def __init__(self, latent_dim, num_channels=3):\n","        super(Generator, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.Linear(latent_dim, 128),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(128, 256),\n","            nn.BatchNorm1d(256),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(256, 512),\n","            nn.BatchNorm1d(512),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(512, 1024),\n","            nn.BatchNorm1d(1024),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(1024, num_channels * 64 * 64),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, z):\n","        img = self.model(z)\n","        img = img.view(img.size(0), 3, 64, 64)\n","        return img\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, num_channels=3):\n","        super(Discriminator, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.Linear(num_channels * 64 * 64, 512),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(512, 256),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(256, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, img):\n","        img_flat = img.view(img.size(0), -1)\n","        validity = self.model(img_flat)\n","        return validity\n","\n","# Generate dataset\n","num_qubits = 3\n","num_samples = 1000\n","quantum_dataset = []\n","\n","for _ in range(num_samples):\n","    statevector = generate_quantum_state(num_qubits)\n","    image = quantum_state_to_image(statevector)\n","    quantum_dataset.append(image)\n","\n","quantum_dataset = np.array(quantum_dataset)\n","quantum_dataset = (quantum_dataset - 127.5) / 127.5  # Normalize to [-1, 1]\n","quantum_dataset = quantum_dataset.transpose(0, 3, 1, 2)  # Change to (N, C, H, W) format\n","\n","# Convert to PyTorch tensors\n","tensor_x = torch.Tensor(quantum_dataset)\n","dataloader = torch.utils.data.DataLoader(tensor_x, batch_size=64, shuffle=True)\n","\n","# Initialize models and optimizers\n","latent_dim = 100\n","generator = Generator(latent_dim)\n","discriminator = Discriminator()\n","\n","optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","\n","criterion = nn.BCELoss()\n","\n","# Training loop\n","num_epochs = 200\n","for epoch in range(num_epochs):\n","    for i, imgs in enumerate(dataloader):\n","        batch_size = imgs.size(0)\n","\n","        # Train Discriminator\n","        real_labels = torch.ones(batch_size, 1)\n","        fake_labels = torch.zeros(batch_size, 1)\n","\n","        optimizer_D.zero_grad()\n","        outputs = discriminator(imgs)\n","        d_loss_real = criterion(outputs, real_labels)\n","        d_loss_real.backward()\n","\n","        z = torch.randn(batch_size, latent_dim)\n","        fake_imgs = generator(z)\n","        outputs = discriminator(fake_imgs.detach())\n","        d_loss_fake = criterion(outputs, fake_labels)\n","        d_loss_fake.backward()\n","\n","        d_loss = d_loss_real + d_loss_fake\n","        optimizer_D.step()\n","\n","        # Train Generator\n","        optimizer_G.zero_grad()\n","        z = torch.randn(batch_size, latent_dim)\n","        fake_imgs = generator(z)\n","        outputs = discriminator(fake_imgs)\n","        g_loss = criterion(outputs, real_labels)\n","        g_loss.backward()\n","        optimizer_G.step()\n","\n","    print(f'Epoch [{epoch+1}/{num_epochs}], d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}')\n","\n","    # Save generated images\n","    if (epoch+1) % 10 == 0:\n","        z = torch.randn(16, latent_dim)\n","        generated_imgs = generator(z).detach().cpu().numpy()\n","        generated_imgs = (generated_imgs + 1) / 2.0  # Rescale to [0, 1]\n","        fig, axs = plt.subplots(4, 4, figsize=(10, 10))\n","        for i in range(4):\n","            for j in range(4):\n","                axs[i, j].imshow(generated_imgs[i*4+j].transpose(1, 2, 0))\n","                axs[i, j].axis('off')\n","        plt.savefig(os.path.join(path, f'generated_images_epoch_{epoch+1}.png'))\n","        plt.close()\n","\n","# Save the trained models\n","torch.save(generator.state_dict(), os.path.join(path, 'generator.pth'))\n","torch.save(discriminator.state_dict(), os.path.join(path, 'discriminator.pth'))"],"metadata":{"id":"ugQzYkqZzwsz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def quantum_state_to_latent(statevector, latent_dim=100):\n","    # This is a simplified mapping. In a more advanced system, you'd use a trained encoder.\n","    normalized_state = np.abs(statevector) / np.linalg.norm(np.abs(statevector))\n","    latent = np.random.randn(latent_dim)\n","    latent[:len(normalized_state)] = normalized_state\n","    return latent\n","\n","# Load the trained generator\n","generator = Generator(latent_dim)\n","generator.load_state_dict(torch.load('generator.pth'))\n","generator.eval()\n","\n","# Generate a quantum state\n","num_qubits = 3\n","quantum_state = generate_quantum_state(num_qubits)\n","\n","# Map quantum state to latent space\n","latent_vector = quantum_state_to_latent(quantum_state, latent_dim)\n","\n","# Generate image from latent vector\n","with torch.no_grad():\n","    latent_tensor = torch.FloatTensor(latent_vector).unsqueeze(0)\n","    generated_img = generator(latent_tensor).squeeze().permute(1, 2, 0).numpy()\n","    generated_img = (generated_img + 1) / 2.0  # Rescale to [0, 1]\n","\n","# Visualize results\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n","\n","plot_state_qsphere(quantum_state, ax=ax1)\n","ax1.set_title('Quantum State')\n","\n","ax2.imshow(generated_img)\n","ax2.set_title('Generated Image')\n","ax2.axis('off')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"5nNVeZQTzwws"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"88u2c3X7zwzl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"FDGmiuvZzw2e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Tu4PQbypzw5m"},"execution_count":null,"outputs":[]}]}